{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/John-G-Thomas/DS-Unit-2-Applied-Modeling/blob/master/module3-permutation-boosting/LS_DS_233.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2ha9OWxf0jw"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hTictxWYih7"
   },
   "source": [
    "# Permutation & Boosting\n",
    "\n",
    "- Get **permutation importances** for model interpretation and feature selection\n",
    "- Use xgboost for **gradient boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMejJg0w8v76"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
    "\n",
    "Libraries:\n",
    "\n",
    "- category_encoders\n",
    "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFQMky3CYih-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install eli5\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "if6nhHuL5Gux"
   },
   "source": [
    "We'll go back to Tanzania Waterpumps for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-TExplb_Slf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Merge train_features.csv & train_labels.csv\n",
    "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
    "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
    "\n",
    "# Read test_features.csv & sample_submission.csv\n",
    "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
    "\n",
    "\n",
    "# Split train into train & val\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
    "    \n",
    "    # Prevent SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    # Also create a \"missing indicator\" column, because the fact that\n",
    "    # values are missing may be a predictive signal.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
    "                       'gps_height', 'population']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "        X[col+'_MISSING'] = X[col].isnull()\n",
    "            \n",
    "    # Drop duplicate columns\n",
    "    duplicates = ['quantity_group', 'payment_type']\n",
    "    X = X.drop(columns=duplicates)\n",
    "    \n",
    "    # Drop recorded_by (never varies) and id (always varies, random)\n",
    "    unusable_variance = ['recorded_by', 'id']\n",
    "    X = X.drop(columns=unusable_variance)\n",
    "    \n",
    "    # Convert date_recorded to datetime\n",
    "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
    "    \n",
    "    # Extract components from date_recorded, then drop the original column\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "    X['month_recorded'] = X['date_recorded'].dt.month\n",
    "    X['day_recorded'] = X['date_recorded'].dt.day\n",
    "    X = X.drop(columns='date_recorded')\n",
    "    \n",
    "    # Engineer feature: how many years from construction_year to date_recorded\n",
    "    X['years'] = X['year_recorded'] - X['construction_year']\n",
    "    X['years_MISSING'] = X['years'].isnull()\n",
    "    \n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "train = wrangle(train)\n",
    "val = wrangle(val)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhg8PQKt_jzP"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'status_group'\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_val = val.drop(columns=target)\n",
    "y_val = val[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8lB4z5l_eml",
    "outputId": "746c398a-ab23-4b34-b5ae-3fc1c32ec83f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8135521885521886\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Validation Accuracy', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0alMokv5Gu7"
   },
   "source": [
    "# Get permutation importances for model interpretation and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5s27C-U5Gu8"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1EbH3oa5Gu9"
   },
   "source": [
    "Default Feature Importances are fast, but Permutation Importances may be more accurate.\n",
    "\n",
    "These links go deeper with explanations and examples:\n",
    "\n",
    "- Permutation Importances\n",
    "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
    "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "- (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HOayKBOYiit"
   },
   "source": [
    "There are three types of feature importances:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4bRhsxENYiiu"
   },
   "source": [
    "### 1. (Default) Feature Importances\n",
    "\n",
    "Fastest, good for first estimates, but be aware:\n",
    "\n",
    "\n",
    "\n",
    ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
    "\n",
    "\n",
    " \n",
    " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNVm6f7mYiiu",
    "outputId": "326f081b-b523-4c7c-a250-1a57e52d67f6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestclassifier']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 20\n",
    "plt.figure(figsize=(10,n/2))\n",
    "plt.title(f'Top {n} features')\n",
    "importances.sort_values()[-n:].plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8HzLcCBYiiv"
   },
   "source": [
    "### 2. Drop-Column Importance\n",
    "\n",
    "The best in theory, but too slow in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQAOlERnYiiw",
    "outputId": "957125ba-7edd-44ca-c2dd-7084c22ff54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy without quantity: 0.7771043771043771\n",
      "Validation Accuracy with quantity: 0.8135521885521886\n",
      "Drop-Column Importance for quantity: 0.03644781144781151\n"
     ]
    }
   ],
   "source": [
    "column  = 'quantity'\n",
    "\n",
    "# Fit without column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train.drop(columns=column), y_train)\n",
    "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
    "print(f'Validation Accuracy without {column}: {score_without}')\n",
    "\n",
    "# Fit with column\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median'), \n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "score_with = pipeline.score(X_val, y_val)\n",
    "print(f'Validation Accuracy with {column}: {score_with}')\n",
    "\n",
    "# Compare the error with & without column\n",
    "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muaYB1Cp5GvF",
    "outputId": "7b9a8ff3-05be-41f6-e43a-bcafcecb5bf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Vu39wGkYiix"
   },
   "source": [
    "### 3. Permutation Importance\n",
    "\n",
    "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
    "\n",
    "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
    "\n",
    "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
    ">\n",
    "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
    ">\n",
    ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
    ">\n",
    ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYCiEx7zYiiy"
   },
   "source": [
    "### Do-It-Yourself way, for intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5CBhllf5GvJ",
    "outputId": "3b83fa81-d9c5-4c9a-9bc6-d822b6901454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enough          6619\n",
       "insufficient    2976\n",
       "dry             1325\n",
       "seasonal         806\n",
       "unknown          154\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[feature].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePk0qb835GvM"
   },
   "outputs": [],
   "source": [
    "X_val_shuffled = X_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TksOf_n2Yiiy",
    "outputId": "851dc486-d4fe-43c6-ed74-073756d706ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290     insufficient\n",
       "47666    insufficient\n",
       "2538           enough\n",
       "53117          enough\n",
       "51817          enough\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = 'quantity'\n",
    "X_val[feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_vdAHn65GvS"
   },
   "outputs": [],
   "source": [
    "X_val_shuffled[feature] = np.random.permutation(X_val[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3J6hz4ba5GvU",
    "outputId": "d1817bd1-86eb-480e-a90a-e6972e2f520e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290           enough\n",
       "47666          enough\n",
       "2538     insufficient\n",
       "53117          enough\n",
       "51817          enough\n",
       "Name: quantity, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_shuffled[feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAxB-ii65GvX",
    "outputId": "15d5b004-3132-46c9-d8db-602f05225878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy with quantity: 0.8135521885521886\n",
      "Validation Accuracy with quantity permuted: 0.7126262626262626\n",
      "Permutation Importance: 0.10092592592592597\n"
     ]
    }
   ],
   "source": [
    "score_with = pipeline.score(X_val, y_val)\n",
    "score_permuted = pipeline.score(X_val_shuffled, y_val)\n",
    "\n",
    "print(f'Validation Accuracy with {feature}: {score_with}')\n",
    "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
    "print(f'Permutation Importance: {score_with - score_permuted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S6WxZScw5Gva"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebMmW8Ao5Gvd"
   },
   "outputs": [],
   "source": [
    "result = permutation_importance(pipeline, X_val, y_val, \n",
    "                                n_repeats=5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZufJyRKM5Gvg"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'feature': X_val.columns,\n",
    "                   'importances_mean': np.round(result['importances_mean'], 3),\n",
    "                   'importances_std': result['importances_std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkJiP4CZ5Gvk",
    "outputId": "68a6e0bf-fe56-403c-c0aa-71401a875a5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importances_mean</th>\n",
       "      <th>importances_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.003164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amount_tsh</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>extraction_type_class</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>waterpoint_type</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>population</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>waterpoint_type_group</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>subvillage</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>payment</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>years</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>construction_year</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>public_meeting</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funder</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>source_class</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>water_quality</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>source</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>longitude_MISSING</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>year_recorded</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>extraction_type</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>extraction_type_group</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>permit</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>district_code</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gps_height</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wpt_name</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>scheme_name</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>region</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>years_MISSING</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lga</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>quality_group</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>construction_year_MISSING</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scheme_management</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>day_recorded</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>month_recorded</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>installer</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>population_MISSING</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gps_height_MISSING</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>latitude_MISSING</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>management</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num_private</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>management_group</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ward</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>source_type</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>region_code</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>basin</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature  importances_mean  importances_std\n",
       "29                   quantity             0.102         0.003164\n",
       "0                  amount_tsh             0.011         0.000550\n",
       "23      extraction_type_class             0.010         0.001120\n",
       "4                   longitude             0.009         0.000940\n",
       "33            waterpoint_type             0.009         0.000866\n",
       "5                    latitude             0.007         0.001098\n",
       "15                 population             0.007         0.000950\n",
       "34      waterpoint_type_group             0.006         0.001824\n",
       "9                  subvillage             0.005         0.000909\n",
       "26                    payment             0.004         0.001657\n",
       "43                      years             0.004         0.001095\n",
       "20          construction_year             0.004         0.000966\n",
       "16             public_meeting             0.003         0.000784\n",
       "1                      funder             0.002         0.000992\n",
       "32               source_class             0.001         0.000465\n",
       "27              water_quality             0.001         0.000492\n",
       "30                     source             0.001         0.001069\n",
       "35          longitude_MISSING             0.001         0.000119\n",
       "40              year_recorded             0.001         0.000444\n",
       "21            extraction_type             0.001         0.001073\n",
       "22      extraction_type_group             0.001         0.000220\n",
       "19                     permit             0.001         0.000648\n",
       "12              district_code             0.001         0.000803\n",
       "2                  gps_height             0.001         0.000522\n",
       "6                    wpt_name             0.001         0.000284\n",
       "18                scheme_name             0.001         0.000655\n",
       "10                     region             0.001         0.001018\n",
       "44              years_MISSING             0.001         0.000290\n",
       "13                        lga             0.001         0.000585\n",
       "28              quality_group            -0.000         0.000289\n",
       "37  construction_year_MISSING             0.000         0.000341\n",
       "17          scheme_management             0.000         0.000674\n",
       "42               day_recorded             0.000         0.000874\n",
       "41             month_recorded             0.000         0.000524\n",
       "3                   installer             0.000         0.000798\n",
       "39         population_MISSING             0.000         0.000180\n",
       "38         gps_height_MISSING             0.000         0.000334\n",
       "36           latitude_MISSING             0.000         0.000124\n",
       "24                 management             0.000         0.001085\n",
       "7                 num_private             0.000         0.000053\n",
       "25           management_group            -0.000         0.000331\n",
       "14                       ward            -0.000         0.000371\n",
       "31                source_type            -0.000         0.000725\n",
       "11                region_code             0.000         0.000742\n",
       "8                       basin            -0.001         0.000691"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='importances_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LYk19SNYii7"
   },
   "source": [
    "### With eli5 library\n",
    "\n",
    "For more documentation on using this library, see:\n",
    "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
    "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
    "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
    "\n",
    "eli5 doesn't work with pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpSemTkFFP8i",
    "outputId": "c28ba586-944c-43af-c4d2-4624c6663d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "transformers = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    SimpleImputer(strategy='median')\n",
    ")\n",
    "\n",
    "X_train_transformed = transformers.fit_transform(X_train)\n",
    "X_val_transformed = transformers.transform(X_val)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a500XdZ35Gvp",
    "outputId": "cb6a17ec-8b6f-4a7e-a0ec-0adfff211563"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eli5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-05b14fc427a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0meli5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m permuter = PermutationImportance(\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'eli5'"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "permuter = PermutationImportance(\n",
    "    model,\n",
    "    scoring='accuracy',\n",
    "    n_iter=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "permuter.fit(X_val_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI2Uc8jW5Gvr",
    "outputId": "67d4922d-0442-4804-bad7-386d836e2a8b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eli5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-0b4df911cddc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m eli5.show_weights(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mpermuter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'eli5' is not defined"
     ]
    }
   ],
   "source": [
    "eli5.show_weights(\n",
    "    permuter,\n",
    "    top=None,\n",
    "    feature_names=X_val.columns.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q07yW9k-Yii8"
   },
   "source": [
    "### We can use importances for feature selection\n",
    "\n",
    "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKbZhPPo5Gvu"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZrPFyEMYii9",
    "outputId": "4c616a01-af5f-442f-92dd-a6ba184bcff3"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-abe3682c1c49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 410\u001b[1;33m                                    dtype=DTYPE, multi_output=True)\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    804\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 646\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\johnt\\anaconda3\\envs\\unit2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                     (type_err,\n\u001b[1;32m--> 100\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    101\u001b[0m             )\n\u001b[0;32m    102\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    #SimpleImputer(strategy='median'), \n",
    "    GradientBoostingClassifier()\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4VOqe0fB5Gvy",
    "outputId": "8a993db2-af20-4c3d-9565-33b93b68716d"
   },
   "outputs": [],
   "source": [
    "print('Training Accuracy:', pipeline.score(X_train, y_train))\n",
    "print('Validation Accuracy:', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fl67bCR7WY6j"
   },
   "source": [
    "# Use xgboost for gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qATo8k925Gv2"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCZ6qdvf5Gv3"
   },
   "source": [
    "In the Random Forest lesson, you learned this advice:\n",
    "\n",
    "#### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
    "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
    "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
    "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
    "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
    "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "61zrE51t5Gv3"
   },
   "source": [
    "Like Random Forest, Gradient Boosting uses ensembles of trees. But the details of the ensembling technique are different:\n",
    "\n",
    "### Understand the difference between boosting & bagging\n",
    "\n",
    "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
    "\n",
    "Here's an excerpt from [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
    "\n",
    ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
    ">\n",
    ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
    ">\n",
    ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
    ">\n",
    ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
    ">\n",
    ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown.\n",
    "\n",
    "This high-level overview is all you need to know for now. If you want to go deeper, we recommend you watch the StatQuest videos on gradient boosting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AivupTLV5Gv3"
   },
   "source": [
    "Let's write some code. We have lots of options for which libraries to use:\n",
    "\n",
    "#### Python libraries for Gradient Boosting\n",
    "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
    "  - Anaconda: already installed\n",
    "  - Google Colab: already installed\n",
    "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
    "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
    "  - Windows: `conda install -c anaconda py-xgboost`\n",
    "  - Google Colab: already installed\n",
    "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
    "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
    "  - Google Colab: already installed\n",
    "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
    "  - Anaconda: `conda install -c conda-forge catboost`\n",
    "  - Google Colab: `pip install catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8tmbBRn5Gv4"
   },
   "source": [
    "### First, boosting with `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_27x2oQw5Gv4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RQ1LgzX5Gv7"
   },
   "source": [
    "In this lesson, you'll use a new library, xgboost — But it has an API that's almost the same as scikit-learn, so it won't be a hard adjustment!\n",
    "\n",
    "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLh4mWNF5Gv7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `XGBClassifier` not found.\n"
     ]
    }
   ],
   "source": [
    "XGBClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsnJRKjfWYph"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-477fa34615c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DymNRig25GwC",
    "outputId": "77b150f4-f530-407a-93e9-cd0536ed68bf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-713f4a57af1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline = make_pipeline(\n\u001b[0;32m      2\u001b[0m     \u001b[0mce\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOrdinalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=6)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0FvI5Tr5GwF",
    "outputId": "d91de3a3-b0b6-418b-b9aa-c2fb5be62c28"
   },
   "outputs": [],
   "source": [
    "print('Training Accuracy:', pipeline.score(X_train, y_train))\n",
    "print('Validation Accuracy:', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eCjVSlD_XJr2"
   },
   "source": [
    "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
    "\n",
    "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
    "\n",
    "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
    "\n",
    "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
    "\n",
    "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
    "\n",
    "#### XGBoost parameters\n",
    "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
    "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNX3IKftXBFS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-02645d8cda9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_val_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m model = XGBClassifier(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mn_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "encoder = ce.OrdinalEncoder()\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators = 1000,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "eval_set = [(X_train_encoded, y_train), \n",
    "            (X_val_encoded, y_val)]\n",
    "\n",
    "model.fit(X_train_encoded, y_train, \n",
    "          eval_set=eval_set, \n",
    "          eval_metric='merror', \n",
    "          early_stopping_rounds=50) # Stop if the score hasn't improved in 50 rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF7-ml6BhRRf"
   },
   "source": [
    "### Try adjusting these hyperparameters\n",
    "\n",
    "#### Random Forest\n",
    "- class_weight (for imbalanced classes)\n",
    "- max_depth (usually high, can try decreasing)\n",
    "- n_estimators (too low underfits, too high wastes time)\n",
    "- min_samples_leaf (increase if overfitting)\n",
    "- max_features (decrease for more diverse trees)\n",
    "\n",
    "#### Xgboost\n",
    "- scale_pos_weight (for imbalanced classes)\n",
    "- max_depth (usually low, can try increasing)\n",
    "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
    "- learning_rate (too low underfits, too high overfits)\n",
    "\n",
    "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaecNuWp5GwK"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint. Complete these tasks for your project, and document your work.\n",
    "\n",
    "- Continue to clean and explore your data. Make exploratory visualizations.\n",
    "- Fit a model. Does it beat your baseline?\n",
    "- Try xgboost.\n",
    "- Get your model's permutation importances.\n",
    "\n",
    "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
    "\n",
    "But, if you aren't ready to try xgboost and permutation importances with your dataset today, you can practice with another dataset instead. You may choose any dataset you've worked with previously."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LS_DS_233.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
