{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('c:/Users/Owen/books_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5111046</td>\n",
       "      <td>A38UEYF5AFDU4I</td>\n",
       "      <td>1416583475</td>\n",
       "      <td>Jason Joyner \"On the journey\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Overview: What would a Mexican housekeeper, a ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fiction with Themes that Matter</td>\n",
       "      <td>1272326400</td>\n",
       "      <td>04 27, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8287159</td>\n",
       "      <td>A3RGUSBU339O2S</td>\n",
       "      <td>B00CPSGLEE</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I began reading as soon as I downloaded and di...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Fast Paced!</td>\n",
       "      <td>1381968000</td>\n",
       "      <td>10 17, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6903249</td>\n",
       "      <td>A194K60CWZ371J</td>\n",
       "      <td>1607746336</td>\n",
       "      <td>Ellybean</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>The Mix &amp; Match Guide to Companion Planting is...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Useful for Any Level Gardener!</td>\n",
       "      <td>1403654400</td>\n",
       "      <td>06 25, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5982295</td>\n",
       "      <td>ARMNRH4HV1W4B</td>\n",
       "      <td>148118928X</td>\n",
       "      <td>Miss g</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>It isn't often I have an opportunity to read a...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Carpenter - Review</td>\n",
       "      <td>1364515200</td>\n",
       "      <td>03 29, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1752754</td>\n",
       "      <td>A3IOBVF6E8SPRL</td>\n",
       "      <td>0373295987</td>\n",
       "      <td>Sue</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I love this book. Very interesting story, char...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Carla Kelly is great, and this is one of her b...</td>\n",
       "      <td>1391558400</td>\n",
       "      <td>02 5, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      reviewerID        asin                   reviewerName  \\\n",
       "0     5111046  A38UEYF5AFDU4I  1416583475  Jason Joyner \"On the journey\"   \n",
       "1     8287159  A3RGUSBU339O2S  B00CPSGLEE                Amazon Customer   \n",
       "2     6903249  A194K60CWZ371J  1607746336                       Ellybean   \n",
       "3     5982295   ARMNRH4HV1W4B  148118928X                         Miss g   \n",
       "4     1752754  A3IOBVF6E8SPRL  0373295987                            Sue   \n",
       "\n",
       "  helpful                                         reviewText  overall  \\\n",
       "0  [0, 0]  Overview: What would a Mexican housekeeper, a ...      5.0   \n",
       "1  [0, 0]  I began reading as soon as I downloaded and di...      4.0   \n",
       "2  [0, 0]  The Mix & Match Guide to Companion Planting is...      5.0   \n",
       "3  [2, 2]  It isn't often I have an opportunity to read a...      4.0   \n",
       "4  [0, 0]  I love this book. Very interesting story, char...      5.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                    Fiction with Themes that Matter      1272326400   \n",
       "1                                        Fast Paced!      1381968000   \n",
       "2                     Useful for Any Level Gardener!      1403654400   \n",
       "3                             The Carpenter - Review      1364515200   \n",
       "4  Carla Kelly is great, and this is one of her b...      1391558400   \n",
       "\n",
       "    reviewTime  \n",
       "0  04 27, 2010  \n",
       "1  10 17, 2013  \n",
       "2  06 25, 2014  \n",
       "3  03 29, 2013  \n",
       "4   02 5, 2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority class baseline accuracy:  0.5590185411124667\n"
     ]
    }
   ],
   "source": [
    "# Get majority class baseline.\n",
    "target = 'overall'\n",
    "majority_class = df[target].mode()[0]\n",
    "baseline_guess = [majority_class] * len(df)\n",
    "print('Majority class baseline accuracy: ', accuracy_score(df[target], baseline_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 60 missing reviews. \n",
    "df = df.dropna(subset=['reviewText']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999940, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create punctuation list.\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create stopwords list.\n",
    "# nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load tokenizer, tagger, parser, NER, and word vectors.\n",
    "parser = English()\n",
    "\n",
    "# Create tokenizer function.\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Create token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "    \n",
    "    # For each token, lemmatize and change to lowercase.\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != '-PRON-'\n",
    "                else word.lower_ for word in mytokens]\n",
    "    # Remove stop words.\n",
    "    mytokens = [word for word in mytokens if word not in stop_words\n",
    "                and word not in punctuations]\n",
    "    # Return preprocessed list of tokens.\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer) # Don't think I need this line.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create features matrix and target vector.\n",
    "X = df['reviewText']\n",
    "y = df[target]\n",
    "\n",
    "# Randomly split data into stratified train (80%) and test (20%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cleaner', <__main__.predictors object at 0x00000296CA4F5C08>),\n",
       "                ('vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function spacy_tokenizer at 0x00000297C6448708>,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                                    random_state=None, solver='lbfgs',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the classifier with mostly default hyperparameters.\n",
    "classifier = LogisticRegression(solver='lbfgs', multi_class='auto', n_jobs=-1,\n",
    "                                random_state=42)\n",
    "\n",
    "# Create pipeline to clean, get bag-of-words review vectors, then run logistic\n",
    "# regression.\n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit the model on train.\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6331979918795128\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create predictions vector from test features.\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Find model accuracy.\n",
    "print(\"Logistic Regression Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit for most of the nlp with spacy and custom transformer to Avinash Navlani. \n",
    "# https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy import en_vectors_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gradient Boosting Decision Tree Classifier\n",
    "# from lightgbm import LGBMClassifier\n",
    "# classifier = LGBMClassifier(objective='multiclass', num_class=5, \n",
    "#                             metric='multi_error', num_threads=6, \n",
    "#                             random_state=42)\n",
    "\n",
    "# # Create pipeline using Bag of Words \n",
    "# pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "#                  ('vectorizer', bow_vector),\n",
    "#                  ('classifier', classifier)])\n",
    "\n",
    "# # model generation\n",
    "# pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    0.559019\n",
       "4.0    0.250450\n",
       "3.0    0.107219\n",
       "2.0    0.046716\n",
       "1.0    0.036596\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "sns.distplot(df[target], kde=False)\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:\n",
    "# 1) Make multiple line graph of the number of each rating over the years.\n",
    "# Like are people giving more 5s as time passes? See if the slope of each line\n",
    "# is the same. Do I need to do time-based split?\n",
    "\n",
    "# 2) In your model, set class_balance/class weights.\n",
    "\n",
    "# 3) Figure out how leakage appllies to your data.\n",
    "\n",
    "# 4) Figure out which accuracy metric to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
