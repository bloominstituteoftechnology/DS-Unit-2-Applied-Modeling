{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fDZ6RaXmGBK"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-hTictxWYih7"
   },
   "source": [
    "# Applied Modeling, Module 3\n",
    "\n",
    "- Visualize and interpret **partial dependence plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoxNYFBXYih9"
   },
   "source": [
    "### Links\n",
    "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
    "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mDthquUBYiiB"
   },
   "source": [
    "\n",
    "\n",
    "### Three types of model explanations this unit:\n",
    "\n",
    "#### 1. Global model explanation: all features in relation to each other _(Yesterday)_\n",
    "- Feature Importances: _Default, fastest, good for first estimates_\n",
    "- Drop-Column Importances: _The best in theory, but much too slow in practice_\n",
    "- Permutaton Importances: _A good compromise!_\n",
    "\n",
    "#### 2. Global model explanation: individual feature(s) in relation to target _(Today)_\n",
    "- Partial Dependence plots\n",
    "\n",
    "#### 3. Individual prediction explanation _(Tomorrow)_\n",
    "- Shapley Values\n",
    "\n",
    "_Note that the coefficients from a linear model give you all three types of explanations!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMt1ghi8_1X4"
   },
   "source": [
    "### Setup\n",
    "\n",
    "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dPcY3kPZ_2em"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "\n",
    "# If you're in Colab...\n",
    "if in_colab:\n",
    "    # Pull files from Github repo\n",
    "    os.chdir('/content')\n",
    "    !git init .\n",
    "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
    "    !git pull origin master\n",
    "    \n",
    "    # Install required python packages\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "    # Change into directory for module\n",
    "    os.chdir('module3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTdq6HMGolY8"
   },
   "outputs": [],
   "source": [
    "# Ignore this warning: https://github.com/dmlc/xgboost/issues/4300\n",
    "# xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "acFiA1u7un9B"
   },
   "source": [
    "## Lending Club: Predict interest rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItMkFUNABo9Y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Stratified sample, 10% of expired Lending Club loans, grades A-D\n",
    "# Source: https://www.lendingclub.com/info/download-data.action\n",
    "history_location = '../data/lending-club/lending-club-subset.csv'\n",
    "history = pd.read_csv(history_location)\n",
    "history['issue_d'] = pd.to_datetime(history['issue_d'], infer_datetime_format=True)\n",
    "\n",
    "# Just use 36 month loans\n",
    "history = history[history.term==' 36 months']\n",
    "\n",
    "# Index & sort by issue date\n",
    "history = history.set_index('issue_d').sort_index()\n",
    "\n",
    "# Clean data, engineer feature, & select subset of features\n",
    "history = history.rename(columns=                     \n",
    "    {'annual_inc': 'Annual Income', \n",
    "     'fico_range_high': 'Credit Score', \n",
    "     'funded_amnt': 'Loan Amount', \n",
    "     'title': 'Loan Purpose'})\n",
    "\n",
    "history['Interest Rate'] = history['int_rate'].str.strip('%').astype(float)\n",
    "history['Monthly Debts'] = history['Annual Income'] / 12 * history['dti'] / 100\n",
    "\n",
    "columns = ['Annual Income', \n",
    "           'Credit Score', \n",
    "           'Loan Amount', \n",
    "           'Loan Purpose', \n",
    "           'Monthly Debts', \n",
    "           'Interest Rate']\n",
    "\n",
    "history = history[columns]\n",
    "history = history.dropna()\n",
    "\n",
    "# Test on the last 10,000 loans,\n",
    "# Validate on the 10,000 before that,\n",
    "# Train on the rest\n",
    "test = history[-10000:]\n",
    "val = history[-20000:-10000]\n",
    "train = history[:-20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-JM8xXECmV0"
   },
   "outputs": [],
   "source": [
    "# Assign to X, y\n",
    "target = 'Interest Rate'\n",
    "features = history.columns.drop('Interest Rate')\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rv9XP3-iMPDW"
   },
   "outputs": [],
   "source": [
    "# The target has some right skew, but it's not too bad\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.distplot(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5kaaMlMwqn4O"
   },
   "source": [
    "### Fit Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7sym2GJ3Ndh2"
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lr = make_pipeline(\n",
    "    ce.OrdinalEncoder(), # Not ideal for Linear Regression \n",
    "    StandardScaler(), \n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print('Linear Regression R^2', lr.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ex2xIb6Gq0LD"
   },
   "source": [
    "### Fit Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IErTkZa3CWT4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "gb = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBRegressor(n_estimators=200, objective='reg:squarederror', n_jobs=-1)\n",
    ")\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_val)\n",
    "print('Gradient Boosting R^2', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_FV6mxql0Qt"
   },
   "source": [
    "### Explaining Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYolPjVZkkFA"
   },
   "outputs": [],
   "source": [
    "example = X_val.iloc[[0]]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cIHdK65GnNDJ"
   },
   "outputs": [],
   "source": [
    "pred = lr.predict(example)[0]\n",
    "print(f'Predicted Interest Rate: {pred:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldbtKx0SlsVW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vary_income(model, example):\n",
    "    print('Vary income, hold other features constant', '\\n')\n",
    "    example = example.copy()\n",
    "    preds = []\n",
    "    for income in range(20000, 200000, 20000):\n",
    "        example['Annual Income'] = income\n",
    "        pred = model.predict(example)[0]\n",
    "        print(f'Predicted Interest Rate: {pred:.3f}%')\n",
    "        print(example.to_string(), '\\n')\n",
    "        preds.append(pred)\n",
    "    print('Difference between predictions')\n",
    "    print(np.diff(preds))\n",
    "        \n",
    "vary_income(lr, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTUldxpImI2h"
   },
   "outputs": [],
   "source": [
    "example2 = X_val.iloc[[2]]\n",
    "vary_income(lr, example2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubzQ-47YtdSD"
   },
   "source": [
    "### Explaining Gradient Boosting???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V77CAqUytaD5"
   },
   "outputs": [],
   "source": [
    "vary_income(gb, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8Rb54SwtmQ8"
   },
   "outputs": [],
   "source": [
    "vary_income(gb, example2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pIPNg2Wsm2ex"
   },
   "source": [
    "## Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5O6s9jisYijI"
   },
   "source": [
    "From [PDPbox documentation](https://pdpbox.readthedocs.io/en/latest/):\n",
    "\n",
    "\n",
    ">**The common headache**: When using black box machine learning algorithms like random forest and boosting, it is hard to understand the relations between predictors and model outcome. For example, in terms of random forest, all we get is the feature importance. Although we can know which feature is significantly influencing the outcome based on the importance calculation, it really sucks that we don’t know in which direction it is influencing. And in most of the real cases, the effect is non-monotonic. We need some powerful tools to help understanding the complex relations between predictors and model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zN2C8QTMYijI"
   },
   "source": [
    "[Animation by Christoph Molnar](https://twitter.com/ChristophMolnar/status/1066398522608635904), author of [_Interpretable Machine Learning_](https://christophm.github.io/interpretable-ml-book/pdp.html#examples)\n",
    "\n",
    "> Partial dependence plots show how a feature affects predictions of a Machine Learning model on average.\n",
    "> 1. Define grid along feature\n",
    "> 2. Model predictions at grid points\n",
    "> 3. Line per data instance -> ICE (Individual Conditional Expectation) curve\n",
    "> 4. Average curves to get a PDP (Partial Dependence Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAP9c1-9vQll"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "examples = pd.concat([example, example2])\n",
    "for income in range(20000, 200000, 20000):\n",
    "    examples['Annual Income'] = income\n",
    "    preds = gb.predict(examples)\n",
    "    for pred in preds:\n",
    "        plt.scatter(income, pred, color='grey')\n",
    "    plt.scatter(income, np.mean(preds), color='red')\n",
    "    plt.title('Partial Dependence')\n",
    "    plt.xlabel('Income')\n",
    "    plt.ylabel('Interest Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOUzbLKpYijB"
   },
   "source": [
    "## Partial Dependence Plots with 1 feature\n",
    "\n",
    "#### PDPbox\n",
    "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
    "- [API Reference: pdp_isolate](https://pdpbox.readthedocs.io/en/latest/pdp_isolate.html)\n",
    "- [API Reference: pdp_plot](https://pdpbox.readthedocs.io/en/latest/pdp_plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2YPeL9n9ZBG3"
   },
   "outputs": [],
   "source": [
    "# Later, when you save matplotlib images to include in blog posts or web apps,\n",
    "# increase the dots per inch (double it), so the text isn't so fuzzy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cegKbw4B43lG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7bIBNtfU3cY"
   },
   "source": [
    "#### You can customize it\n",
    "\n",
    "PDPbox\n",
    "- [API Reference: PDPIsolate](https://pdpbox.readthedocs.io/en/latest/PDPIsolate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PU5sTdohVwDH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LOu_hUU6YijJ"
   },
   "source": [
    "## Partial Dependence Plots with 2 features\n",
    "\n",
    "See interactions!\n",
    "\n",
    "PDPbox\n",
    "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
    "- [API Reference: pdp_interact](https://pdpbox.readthedocs.io/en/latest/pdp_interact.html)\n",
    "- [API Reference: pdp_interact_plot](https://pdpbox.readthedocs.io/en/latest/pdp_interact_plot.html)\n",
    "\n",
    "Be aware of a bug in PDPBox version <= 0.20:\n",
    "- With the `pdp_interact_plot` function, `plot_type='contour'` gets an error, but `plot_type='grid'` works\n",
    "- This will be fixed in the next release of PDPbox: https://github.com/SauceCat/PDPbox/issues/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edL2X3QtYijJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0zF-MIh47JK"
   },
   "source": [
    "### 3D with Plotly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVI9Y93Z0t4B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7GKnVW01bBK"
   },
   "source": [
    "# Partial Dependence Plots with categorical features\n",
    "\n",
    "1. I recommend you use Ordinal Encoder, outside of a pipeline, to encode your data first. (If there is a natural ordering, then take the time to encode it that way, instead of random integers.) Then use the encoded data with pdpbox.\n",
    "2. There's some extra work to get readable category names on your plot, instead of integer category codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKd-dI7Y1LSL"
   },
   "outputs": [],
   "source": [
    "# Fit a model on Titanic data\n",
    "import category_encoders as ce\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df.age = df.age.fillna(df.age.median())\n",
    "df = df.drop(columns='deck')\n",
    "df = df.dropna()\n",
    "\n",
    "target = 'survived'\n",
    "features = df.columns.drop(['survived', 'alive'])\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Use Ordinal \n",
    "encoder = ce.OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izClfuUV1lSt"
   },
   "outputs": [],
   "source": [
    "# Use Pdpbox\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pdpbox import pdp\n",
    "feature = 'sex'\n",
    "pdp_dist = pdp.pdp_isolate(model=model, dataset=X_encoded, model_features=features, feature=feature)\n",
    "pdp.pdp_plot(pdp_dist, feature);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuQPHCti1opV"
   },
   "outputs": [],
   "source": [
    "# Look at the encoder's mappings\n",
    "encoder.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5UVHSuQ1toP"
   },
   "outputs": [],
   "source": [
    "pdp.pdp_plot(pdp_dist, feature)\n",
    "\n",
    "# Manually change the xticks labels\n",
    "plt.xticks([1, 2], ['male', 'female']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbaVTJIa104W"
   },
   "outputs": [],
   "source": [
    "# Let's automate it\n",
    "\n",
    "feature = 'sex'\n",
    "for item in encoder.mapping:\n",
    "    if item['col'] == feature:\n",
    "        feature_mapping = item['mapping']\n",
    "\n",
    "feature_mapping = feature_mapping[feature_mapping.index.dropna()]\n",
    "category_names = feature_mapping.index.tolist()\n",
    "category_codes = feature_mapping.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSSoKtbi14OP"
   },
   "outputs": [],
   "source": [
    "pdp.pdp_plot(pdp_dist, feature)\n",
    "\n",
    "# Automatically change the xticks labels\n",
    "plt.xticks(category_codes, category_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0R4gnZY199a"
   },
   "outputs": [],
   "source": [
    "features = ['sex', 'age']\n",
    "\n",
    "interaction = pdp_interact(\n",
    "    model=model, \n",
    "    dataset=X_encoded, \n",
    "    model_features=X_encoded.columns, \n",
    "    features=features\n",
    ")\n",
    "\n",
    "pdp_interact_plot(interaction, plot_type='grid', feature_names=features);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAhHHHO52OJt"
   },
   "outputs": [],
   "source": [
    "pdp = interaction.pdp.pivot_table(\n",
    "    values='preds', \n",
    "    columns=features[0], # First feature on x axis\n",
    "    index=features[1]    # Next feature on y axis\n",
    ")[::-1]  # Reverse the index order so y axis is ascending\n",
    "\n",
    "pdp = pdp.rename(columns=dict(zip(category_codes, category_names)))\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(pdp, annot=True, fmt='.2f', cmap='viridis')\n",
    "plt.title('Partial Dependence of Titanic survival, on sex & age');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS7_lesson_applied_modeling_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
