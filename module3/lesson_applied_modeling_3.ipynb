{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_applied_modeling_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Applied Modeling, Module 3\n",
        "\n",
        "### Objective\n",
        "- Visualize and interpret partial dependence plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Links\n",
        "- [Kaggle / Dan Becker: Machine Learning Explainability — Partial Dependence Plots](https://www.kaggle.com/dansbecker/partial-plots)\n",
        "- [Christoph Molnar: Interpretable Machine Learning — Partial Dependence Plots](https://christophm.github.io/interpretable-ml-book/pdp.html) + [animated explanation](https://twitter.com/ChristophMolnar/status/1066398522608635904)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDthquUBYiiB"
      },
      "source": [
        "\n",
        "\n",
        "### Three types of model explanations this unit:\n",
        "\n",
        "#### 1. Global model explanation: all features in relation to each other _(Last Week)_\n",
        "- Feature Importances: _Default, fastest, good for first estimates_\n",
        "- Drop-Column Importances: _The best in theory, but much too slow in practice_\n",
        "- Permutaton Importances: _A good compromise!_\n",
        "\n",
        "#### 2. Global model explanation: individual feature(s) in relation to target _(Today)_\n",
        "- Partial Dependence plots\n",
        "\n",
        "#### 3. Individual prediction explanation _(Tomorrow)_\n",
        "- Shapley Values\n",
        "\n",
        "_Note that the coefficients from a linear model give you all three types of explanations!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMt1ghi8_1X4",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "#### If you're using [Anaconda](https://www.anaconda.com/distribution/) locally\n",
        "\n",
        "Install required Python packages, if you haven't already:\n",
        "\n",
        "- [category_encoders](https://github.com/scikit-learn-contrib/categorical-encoding), version >= 2.0: `conda install -c conda-forge category_encoders` / `pip install category_encoders`\n",
        "- [PDPbox](https://github.com/SauceCat/PDPbox): `pip install pdpbox`\n",
        "- [Plotly](https://medium.com/plotly/plotly-py-4-0-is-here-offline-only-express-first-displayable-anywhere-fc444e5659ee), version >= 4.0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPcY3kPZ_2em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python package:\n",
        "    # category_encoders, version >= 2.0\n",
        "    !pip install --upgrade category_encoders pdpbox plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acFiA1u7un9B",
        "colab_type": "text"
      },
      "source": [
        "## Lending Club: Predict interest rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItMkFUNABo9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Stratified sample, 10% of expired Lending Club loans, grades A-D\n",
        "# Source: https://www.lendingclub.com/info/download-data.action\n",
        "history_location = '../data/lending-club/lending-club-subset.csv'\n",
        "history = pd.read_csv(history_location)\n",
        "history['issue_d'] = pd.to_datetime(history['issue_d'], infer_datetime_format=True)\n",
        "\n",
        "# Just use 36 month loans\n",
        "history = history[history.term==' 36 months']\n",
        "\n",
        "# Index & sort by issue date\n",
        "history = history.set_index('issue_d').sort_index()\n",
        "\n",
        "# Clean data, engineer feature, & select subset of features\n",
        "history = history.rename(columns=                     \n",
        "    {'annual_inc': 'Annual Income', \n",
        "     'fico_range_high': 'Credit Score', \n",
        "     'funded_amnt': 'Loan Amount', \n",
        "     'title': 'Loan Purpose'})\n",
        "\n",
        "history['Interest Rate'] = history['int_rate'].str.strip('%').astype(float)\n",
        "history['Monthly Debts'] = history['Annual Income'] / 12 * history['dti'] / 100\n",
        "\n",
        "columns = ['Annual Income', \n",
        "           'Credit Score', \n",
        "           'Loan Amount', \n",
        "           'Loan Purpose', \n",
        "           'Monthly Debts', \n",
        "           'Interest Rate']\n",
        "\n",
        "history = history[columns]\n",
        "history = history.dropna()\n",
        "\n",
        "# Test on the last 10,000 loans,\n",
        "# Validate on the 10,000 before that,\n",
        "# Train on the rest\n",
        "test = history[-10000:]\n",
        "val = history[-20000:-10000]\n",
        "train = history[:-20000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-JM8xXECmV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign to X, y\n",
        "target = 'Interest Rate'\n",
        "features = history.columns.drop('Interest Rate')\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv9XP3-iMPDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The target has some right skew.\n",
        "# It's not bad, but we'll log transform anyways\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.distplot(y_train);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyfaRNu3MoLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Log transform the target\n",
        "import numpy as np\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_val_log = np.log1p(y_val)\n",
        "y_test_log = np.log1p(y_test)\n",
        "\n",
        "# Plot the transformed target's distribution\n",
        "sns.distplot(y_train_log);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kaaMlMwqn4O",
        "colab_type": "text"
      },
      "source": [
        "### Fit Linear Regression model, with original target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sym2GJ3Ndh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "lr = make_pipeline(\n",
        "    ce.OrdinalEncoder(), # Not ideal for Linear Regression \n",
        "    StandardScaler(), \n",
        "    LinearRegression()\n",
        ")\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "print('Linear Regression R^2', lr.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex2xIb6Gq0LD",
        "colab_type": "text"
      },
      "source": [
        "### Fit Gradient Boosting model, with log transformed target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IErTkZa3CWT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "gb = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBRegressor(n_estimators=200, objective='reg:squarederror', n_jobs=-1)\n",
        ")\n",
        "\n",
        "gb.fit(X_train, y_train_log)\n",
        "# print('Gradient Boosting R^2', gb.score(X_val, y_val_log))\n",
        "# Convert back away from log space"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_FV6mxql0Qt",
        "colab_type": "text"
      },
      "source": [
        "### Explaining Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYolPjVZkkFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = X_val.iloc[[0]]\n",
        "example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIHdK65GnNDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = lr.predict(example)[0]\n",
        "print(f'Predicted Interest Rate: {pred:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldbtKx0SlsVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, example, log=False):\n",
        "    print('Vary income, hold other features constant', '\\n')\n",
        "    example = example.copy()\n",
        "    preds = []\n",
        "    for income in range(20000, 200000, 20000):\n",
        "        example['Annual Income'] = income\n",
        "        pred = model.predict(example)[0]\n",
        "        if log:\n",
        "            pred = np.expm1(pred)\n",
        "        print(f'Predicted Interest Rate: {pred:.3f}%')\n",
        "        print(example.to_string(), '\\n')\n",
        "        preds.append(pred)\n",
        "    print('Difference between predictions')\n",
        "    print(np.diff(preds))\n",
        "        \n",
        "predict(lr, example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTUldxpImI2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example2 = X_val.iloc[[2]]\n",
        "predict(lr, example2);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubzQ-47YtdSD",
        "colab_type": "text"
      },
      "source": [
        "### Explaining Gradient Boosting???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V77CAqUytaD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(gb, example, log=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Rb54SwtmQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(gb, example2, log=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIPNg2Wsm2ex",
        "colab_type": "text"
      },
      "source": [
        "## Partial Dependence Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5O6s9jisYijI"
      },
      "source": [
        "From [PDPbox documentation](https://pdpbox.readthedocs.io/en/latest/):\n",
        "\n",
        "\n",
        ">**The common headache**: When using black box machine learning algorithms like random forest and boosting, it is hard to understand the relations between predictors and model outcome. For example, in terms of random forest, all we get is the feature importance. Although we can know which feature is significantly influencing the outcome based on the importance calculation, it really sucks that we don’t know in which direction it is influencing. And in most of the real cases, the effect is non-monotonic. We need some powerful tools to help understanding the complex relations between predictors and model prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zN2C8QTMYijI"
      },
      "source": [
        "[Animation by Christoph Molnar](https://twitter.com/ChristophMolnar/status/1066398522608635904), author of [_Interpretable Machine Learning_](https://christophm.github.io/interpretable-ml-book/pdp.html#examples)\n",
        "\n",
        "> Partial dependence plots show how a feature affects predictions of a Machine Learning model on average.\n",
        "> 1. Define grid along feature\n",
        "> 2. Model predictions at grid points\n",
        "> 3. Line per data instance -> ICE (Individual Conditional Expectation) curve\n",
        "> 4. Average curves to get a PDP (Partial Dependence Plot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAP9c1-9vQll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "examples = pd.concat([example, example2])\n",
        "for income in range(20000, 200000, 20000):\n",
        "    examples['Annual Income'] = income\n",
        "    preds_log = gb.predict(examples)\n",
        "    preds = np.expm1(preds_log)\n",
        "    for pred in preds:\n",
        "        plt.scatter(income, pred, color='grey')\n",
        "    plt.scatter(income, np.mean(preds), color='red')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QOUzbLKpYijB"
      },
      "source": [
        "## Partial Dependence Plots with 1 feature\n",
        "\n",
        "#### PDPbox\n",
        "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
        "- [API Reference: pdp_isolate](https://pdpbox.readthedocs.io/en/latest/pdp_isolate.html)\n",
        "- [API Reference: pdp_plot](https://pdpbox.readthedocs.io/en/latest/pdp_plot.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YPeL9n9ZBG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Later, when you save matplotlib images to include in blog posts or web apps,\n",
        "# increase the dots per inch (double it), so the text isn't so fuzzy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 72"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cegKbw4B43lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7bIBNtfU3cY",
        "colab_type": "text"
      },
      "source": [
        "#### You can customize it\n",
        "\n",
        "PDPbox\n",
        "- [API Reference: PDPIsolate](https://pdpbox.readthedocs.io/en/latest/PDPIsolate.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU5sTdohVwDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LOu_hUU6YijJ"
      },
      "source": [
        "## Partial Dependence Plots with 2 features\n",
        "\n",
        "See interactions!\n",
        "\n",
        "PDPbox\n",
        "- [Gallery](https://github.com/SauceCat/PDPbox#gallery)\n",
        "- [API Reference: pdp_interact](https://pdpbox.readthedocs.io/en/latest/pdp_interact.html)\n",
        "- [API Reference: pdp_interact_plot](https://pdpbox.readthedocs.io/en/latest/pdp_interact_plot.html)\n",
        "\n",
        "Be aware of a bug in PDPBox version <= 0.20:\n",
        "- With the `pdp_interact_plot` function, `plot_type='contour'` gets an error, but `plot_type='grid'` works\n",
        "- This will be fixed in the next release of PDPbox: https://github.com/SauceCat/PDPbox/issues/40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edL2X3QtYijJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0zF-MIh47JK",
        "colab_type": "text"
      },
      "source": [
        "### 3D with Plotly!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVI9Y93Z0t4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7GKnVW01bBK",
        "colab_type": "text"
      },
      "source": [
        "# Partial Dependence Plots with categorical features\n",
        "\n",
        "1. I recommend you use Ordinal Encoder, outside of a pipeline, to encode your data first. Then use the encoded data with pdpbox.\n",
        "2. There's some extra work to get readable category names on your plot, instead of integer category codes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKd-dI7Y1LSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit a model on Titanic data\n",
        "import category_encoders as ce\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "df = sns.load_dataset('titanic')\n",
        "df.age = df.age.fillna(df.age.median())\n",
        "df = df.drop(columns='deck')\n",
        "df = df.dropna()\n",
        "\n",
        "target = 'survived'\n",
        "features = df.columns.drop(['survived', 'alive'])\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Use Ordinal \n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_encoded, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izClfuUV1lSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Pdpbox\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from pdpbox import pdp\n",
        "feature = 'sex'\n",
        "pdp_dist = pdp.pdp_isolate(model=model, dataset=X_encoded, model_features=features, feature=feature)\n",
        "pdp.pdp_plot(pdp_dist, feature);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuQPHCti1opV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Look at the encoder's mappings\n",
        "encoder.mapping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5UVHSuQ1toP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdp.pdp_plot(pdp_dist, feature)\n",
        "\n",
        "# Manually change the xticks labels\n",
        "plt.xticks([1, 2], ['male', 'female']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbaVTJIa104W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's automate it\n",
        "\n",
        "feature = 'sex'\n",
        "for item in encoder.mapping:\n",
        "    if item['col'] == feature:\n",
        "        feature_mapping = item['mapping']\n",
        "\n",
        "feature_mapping = feature_mapping[feature_mapping.index.dropna()]\n",
        "category_names = feature_mapping.index.tolist()\n",
        "category_codes = feature_mapping.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSSoKtbi14OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use Pdpbox\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from pdpbox import pdp\n",
        "feature = 'sex'\n",
        "pdp_dist = pdp.pdp_isolate(model=model, dataset=X_encoded, model_features=features, feature=feature)\n",
        "pdp.pdp_plot(pdp_dist, feature)\n",
        "\n",
        "# Automatically change the xticks labels\n",
        "plt.xticks(category_codes, category_names);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0R4gnZY199a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['sex', 'age']\n",
        "\n",
        "interaction = pdp_interact(\n",
        "    model=model, \n",
        "    dataset=X_encoded, \n",
        "    model_features=X_encoded.columns, \n",
        "    features=features\n",
        ")\n",
        "\n",
        "pdp_interact_plot(interaction, plot_type='grid', feature_names=features);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAhHHHO52OJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pdp = interaction.pdp.pivot_table(\n",
        "    values='preds', \n",
        "    columns=features[0], # First feature on x axis\n",
        "    index=features[1]    # Next feature on y axis\n",
        ")[::-1]  # Reverse the index order so y axis is ascending\n",
        "\n",
        "pdp = pdp.rename(columns=dict(zip(category_codes, category_names)))\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(pdp, annot=True, fmt='.2f', cmap='viridis')\n",
        "plt.title('Partial Dependence of Titanic survival, on sex & age');"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}