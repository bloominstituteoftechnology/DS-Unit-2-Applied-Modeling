{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit 2 - Sprint 3 - Module 2 - IN LESSON",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lechemrc/DS-Unit-2-Applied-Modeling/blob/master/module3/Unit_2_Sprint_3_Module_2_IN_LESSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ha9OWxf0jw",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Applied Modeling, Module 2\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMejJg0w8v76",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "outputId": "bd51cf39-6947-4d05-bf63-c4b0236d6235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Total 77 (delta 0), reused 0 (delta 0), pack-reused 77\u001b[K\n",
            "Unpacking objects: 100% (77/77), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Checking out files: 100% (26/26), done.\n",
            "Collecting category_encoders==2.0.0 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 586kB/s \n",
            "\u001b[?25hCollecting eli5==0.10.1 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pandas-profiling==2.3.0 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.5MB/s \n",
            "\u001b[?25hCollecting pdpbox==0.2.0 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 476kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Collecting shap==0.30.0 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/98/16829410426bdd08b836c30e164c56646d6a102afb9eadd81a6bd3a8bb65/shap-0.30.0.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 40.3MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/46/903ea822d83187bb8b354fcb3d085fb10b7787be39f9cf1628bc6ef8f9c9/pytest-5.2.0-py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Collecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.2)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.23)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/ed/1cb8e7b85a31807aa0bff8b3e60935370bed7e141df8b530aac6352bddff/pylint-2.4.2-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 50.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Collecting astroid<2.4,>=2.3.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e1/74a63c85c501c29c52da5be604c025e368f4dd77daf1fa13c878a33e5a36/astroid-2.3.1-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 55.3MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt==1.11.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 46.0MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.4.* (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 19.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-profiling, pdpbox, shap, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=f01464ea2197a7b8d1cd112cfe94b382ea058a488e8e829a9bcdc9c0dba421c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.0-cp36-none-any.whl size=57690723 sha256=02e80cc4a99e2ba7f39576bb1a2bac16d95abb3bcb838ed09faaa2fbcb805a44\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.30.0-cp36-cp36m-linux_x86_64.whl size=356738 sha256=3488588d14cf4aea71df7a4d2aef53f7c9b8704227cf6bb83a22c17169d759ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/7a/5b/34feab81170fb8bf642a7536b5127e54e00bce373564435808\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=add541923465ab99de7a67072d4d5e671ef720e939d6dd9df03b513b734bb89f\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=d78f42de539b6c50e034a060d733baa986c8003b6cbe862154144796d219aaf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling pdpbox shap htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, eli5, htmlmin, pluggy, pytest, typed-ast, lazy-object-proxy, astroid, mccabe, isort, pylint, pytest-pylint, phik, confuse, pandas-profiling, pdpbox, shap\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.3.1 category-encoders-2.0.0 confuse-1.0.0 eli5-0.10.1 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 pdpbox-0.2.0 phik-0.9.8 pluggy-0.13.0 pylint-2.4.2 pytest-5.2.0 pytest-pylint-0.14.1 shap-0.30.0 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TExplb_Slf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhg8PQKt_jzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8lB4z5l_eml",
        "colab_type": "code",
        "outputId": "0fbd338a-c26d-47d1-f887-1473f5dea790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "# 3 types of feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "## 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "outputId": "e1835049-46d6-4f63-ed28-fdb16f19a48b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJOCAYAAACzyR8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n99A0istCZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "## 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "outputId": "a03b81c2-fad3-4a11-8f84-ffd89b1eca68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "column = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7771043771043771\n",
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Drop-Column Importance for quantity: 0.03644781144781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "## 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbbAFVwfGX1p",
        "colab_type": "code",
        "outputId": "9a9a50a6-f404-4a43-da66-7c783516397f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# TODO \n",
        "\n",
        "feature = 'quantity'\n",
        "X_val[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQMmKGBZunu4",
        "colab_type": "code",
        "outputId": "512c22de-d372-4655-89c3-9b220678e1c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_val[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tthHh0JDuuVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikHiib-mvGIQ",
        "colab_type": "code",
        "outputId": "9f1735cf-ba0c-417e-b5d5-cc8c0ddb0e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666          enough\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYGNJPoNvLF3",
        "colab_type": "code",
        "outputId": "5081068b-52c1-4ed4-93d5-4ad20405bc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X_val_permuted[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THUACH_ivciW",
        "colab_type": "code",
        "outputId": "a022c4d3-d827-47d4-a65a-d3ab8d9717b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')\n",
        "\n",
        "# This permutation importance is less likely to be biased"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Validation Accuracy with quantity permuted: 0.7173400673400674\n",
            "Permutation Importance: 0.0962121212121212\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pYjHA4dvx02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uooPLjX0HkQv",
        "colab_type": "code",
        "outputId": "a6dfc066-8c38-43de-8461-b05b98562b70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.fit_transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NZWJF_Vwys-",
        "colab_type": "code",
        "outputId": "9333a115-37ae-4b51-9055-cd10de7139a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring='accuracy',\n",
        "    n_iter=2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None,\n",
        "    feature_names = feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1007\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.83%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0107\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0103\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.99%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0101\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0095\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0077\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.86%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0072\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.13%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0063\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.07%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0036\n",
              "                \n",
              "                    &plusmn; 0.0035\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0034\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0032\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0027\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0025\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.72%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0020\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0012\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.60%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.60%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.66%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0004\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0008\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0016\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB1l3Xewxcxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VsJ483wMAQ6",
        "colab_type": "code",
        "outputId": "40b6f763-b0f6-4a9c-a50d-0c9c318ec8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO\n",
        "\n",
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47520, 39)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsxXU4BRzUVi",
        "colab_type": "code",
        "outputId": "6abee8ff-96ee-4ff7-c003-38a0552c1b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_val = X_val[features]\n",
        "X_val.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11880, 39)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Lo9Q6ZzbNh",
        "colab_type": "code",
        "outputId": "b137e164-38d9-45a1-96ee-baedecbe3822",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median'),\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8125420875420876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-dgWlMPzrmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl67bCR7WY6j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Use xgboost for gradient boosting\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnJRKjfWYph",
        "colab_type": "code",
        "outputId": "bf7cca1d-6992-43ce-81da-c576c2b96f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO \n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7457070707070707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZDK8t7k0lxb",
        "colab_type": "code",
        "outputId": "f8791bab-5fc4-49b1-a90f-a6c23b6771ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7457070707070707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKRIA1yM1Vjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubb7Ot6OZcK1",
        "colab_type": "text"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCjVSlD_XJr2",
        "colab_type": "text"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scp2SgxKR-6x",
        "colab_type": "code",
        "outputId": "db499f98-5935-4884-96ee-d7cd8b42230f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TODO\n",
        "\n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 39), (11880, 39), (47520, 39), (11880, 39))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccuqasCH3Vg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_set = [(X_train_encoded, y_train), (X_val_encoded, y_val)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd9bzv-p3bed",
        "colab_type": "code",
        "outputId": "e6200de5-5af8-4401-95cb-78b87ec10882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=7,\n",
        "    learning_rate=0.1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train_encoded, y_train, eval_set=eval_set, eval_metric='merror', early_stopping_rounds=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250884\tvalidation_1-merror:0.261953\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.252294\tvalidation_1-merror:0.264057\n",
            "[2]\tvalidation_0-merror:0.251747\tvalidation_1-merror:0.264731\n",
            "[3]\tvalidation_0-merror:0.249895\tvalidation_1-merror:0.262037\n",
            "[4]\tvalidation_0-merror:0.248864\tvalidation_1-merror:0.26069\n",
            "[5]\tvalidation_0-merror:0.24678\tvalidation_1-merror:0.257239\n",
            "[6]\tvalidation_0-merror:0.243687\tvalidation_1-merror:0.255051\n",
            "[7]\tvalidation_0-merror:0.240404\tvalidation_1-merror:0.250421\n",
            "[8]\tvalidation_0-merror:0.2379\tvalidation_1-merror:0.248316\n",
            "[9]\tvalidation_0-merror:0.235816\tvalidation_1-merror:0.247054\n",
            "[10]\tvalidation_0-merror:0.234975\tvalidation_1-merror:0.24596\n",
            "[11]\tvalidation_0-merror:0.23388\tvalidation_1-merror:0.245118\n",
            "[12]\tvalidation_0-merror:0.233228\tvalidation_1-merror:0.245286\n",
            "[13]\tvalidation_0-merror:0.231776\tvalidation_1-merror:0.244529\n",
            "[14]\tvalidation_0-merror:0.232008\tvalidation_1-merror:0.244529\n",
            "[15]\tvalidation_0-merror:0.230535\tvalidation_1-merror:0.243855\n",
            "[16]\tvalidation_0-merror:0.229104\tvalidation_1-merror:0.241835\n",
            "[17]\tvalidation_0-merror:0.228325\tvalidation_1-merror:0.241919\n",
            "[18]\tvalidation_0-merror:0.227125\tvalidation_1-merror:0.239899\n",
            "[19]\tvalidation_0-merror:0.226515\tvalidation_1-merror:0.238973\n",
            "[20]\tvalidation_0-merror:0.225526\tvalidation_1-merror:0.238973\n",
            "[21]\tvalidation_0-merror:0.224495\tvalidation_1-merror:0.237626\n",
            "[22]\tvalidation_0-merror:0.22298\tvalidation_1-merror:0.23569\n",
            "[23]\tvalidation_0-merror:0.221843\tvalidation_1-merror:0.235522\n",
            "[24]\tvalidation_0-merror:0.221044\tvalidation_1-merror:0.235774\n",
            "[25]\tvalidation_0-merror:0.220244\tvalidation_1-merror:0.235269\n",
            "[26]\tvalidation_0-merror:0.218939\tvalidation_1-merror:0.234428\n",
            "[27]\tvalidation_0-merror:0.217151\tvalidation_1-merror:0.232492\n",
            "[28]\tvalidation_0-merror:0.215109\tvalidation_1-merror:0.230892\n",
            "[29]\tvalidation_0-merror:0.213636\tvalidation_1-merror:0.229882\n",
            "[30]\tvalidation_0-merror:0.212563\tvalidation_1-merror:0.228283\n",
            "[31]\tvalidation_0-merror:0.211132\tvalidation_1-merror:0.227357\n",
            "[32]\tvalidation_0-merror:0.209996\tvalidation_1-merror:0.227104\n",
            "[33]\tvalidation_0-merror:0.209049\tvalidation_1-merror:0.226683\n",
            "[34]\tvalidation_0-merror:0.207765\tvalidation_1-merror:0.226515\n",
            "[35]\tvalidation_0-merror:0.206734\tvalidation_1-merror:0.226347\n",
            "[36]\tvalidation_0-merror:0.205724\tvalidation_1-merror:0.225589\n",
            "[37]\tvalidation_0-merror:0.204882\tvalidation_1-merror:0.225168\n",
            "[38]\tvalidation_0-merror:0.203998\tvalidation_1-merror:0.224158\n",
            "[39]\tvalidation_0-merror:0.20221\tvalidation_1-merror:0.222475\n",
            "[40]\tvalidation_0-merror:0.200968\tvalidation_1-merror:0.221633\n",
            "[41]\tvalidation_0-merror:0.199474\tvalidation_1-merror:0.220539\n",
            "[42]\tvalidation_0-merror:0.198695\tvalidation_1-merror:0.220707\n",
            "[43]\tvalidation_0-merror:0.197769\tvalidation_1-merror:0.220286\n",
            "[44]\tvalidation_0-merror:0.196275\tvalidation_1-merror:0.219613\n",
            "[45]\tvalidation_0-merror:0.195707\tvalidation_1-merror:0.219108\n",
            "[46]\tvalidation_0-merror:0.194739\tvalidation_1-merror:0.218266\n",
            "[47]\tvalidation_0-merror:0.194192\tvalidation_1-merror:0.217172\n",
            "[48]\tvalidation_0-merror:0.193287\tvalidation_1-merror:0.217172\n",
            "[49]\tvalidation_0-merror:0.192466\tvalidation_1-merror:0.216667\n",
            "[50]\tvalidation_0-merror:0.19194\tvalidation_1-merror:0.216835\n",
            "[51]\tvalidation_0-merror:0.191225\tvalidation_1-merror:0.216077\n",
            "[52]\tvalidation_0-merror:0.190278\tvalidation_1-merror:0.215152\n",
            "[53]\tvalidation_0-merror:0.18971\tvalidation_1-merror:0.21431\n",
            "[54]\tvalidation_0-merror:0.189205\tvalidation_1-merror:0.214478\n",
            "[55]\tvalidation_0-merror:0.188279\tvalidation_1-merror:0.212879\n",
            "[56]\tvalidation_0-merror:0.187184\tvalidation_1-merror:0.212795\n",
            "[57]\tvalidation_0-merror:0.186385\tvalidation_1-merror:0.211953\n",
            "[58]\tvalidation_0-merror:0.185501\tvalidation_1-merror:0.211448\n",
            "[59]\tvalidation_0-merror:0.18487\tvalidation_1-merror:0.211448\n",
            "[60]\tvalidation_0-merror:0.184364\tvalidation_1-merror:0.211364\n",
            "[61]\tvalidation_0-merror:0.183586\tvalidation_1-merror:0.210859\n",
            "[62]\tvalidation_0-merror:0.183123\tvalidation_1-merror:0.21069\n",
            "[63]\tvalidation_0-merror:0.182302\tvalidation_1-merror:0.210354\n",
            "[64]\tvalidation_0-merror:0.182029\tvalidation_1-merror:0.210522\n",
            "[65]\tvalidation_0-merror:0.181839\tvalidation_1-merror:0.209512\n",
            "[66]\tvalidation_0-merror:0.181145\tvalidation_1-merror:0.209259\n",
            "[67]\tvalidation_0-merror:0.180745\tvalidation_1-merror:0.209259\n",
            "[68]\tvalidation_0-merror:0.180156\tvalidation_1-merror:0.208923\n",
            "[69]\tvalidation_0-merror:0.179735\tvalidation_1-merror:0.208923\n",
            "[70]\tvalidation_0-merror:0.179398\tvalidation_1-merror:0.208754\n",
            "[71]\tvalidation_0-merror:0.178767\tvalidation_1-merror:0.208923\n",
            "[72]\tvalidation_0-merror:0.17822\tvalidation_1-merror:0.208923\n",
            "[73]\tvalidation_0-merror:0.177946\tvalidation_1-merror:0.209091\n",
            "[74]\tvalidation_0-merror:0.176684\tvalidation_1-merror:0.208502\n",
            "[75]\tvalidation_0-merror:0.176157\tvalidation_1-merror:0.207997\n",
            "[76]\tvalidation_0-merror:0.175231\tvalidation_1-merror:0.207576\n",
            "[77]\tvalidation_0-merror:0.174958\tvalidation_1-merror:0.208165\n",
            "[78]\tvalidation_0-merror:0.174579\tvalidation_1-merror:0.206313\n",
            "[79]\tvalidation_0-merror:0.17399\tvalidation_1-merror:0.206145\n",
            "[80]\tvalidation_0-merror:0.173695\tvalidation_1-merror:0.205556\n",
            "[81]\tvalidation_0-merror:0.17338\tvalidation_1-merror:0.205135\n",
            "[82]\tvalidation_0-merror:0.173211\tvalidation_1-merror:0.205219\n",
            "[83]\tvalidation_0-merror:0.172727\tvalidation_1-merror:0.204798\n",
            "[84]\tvalidation_0-merror:0.172306\tvalidation_1-merror:0.204798\n",
            "[85]\tvalidation_0-merror:0.171928\tvalidation_1-merror:0.204714\n",
            "[86]\tvalidation_0-merror:0.171907\tvalidation_1-merror:0.204545\n",
            "[87]\tvalidation_0-merror:0.17138\tvalidation_1-merror:0.204209\n",
            "[88]\tvalidation_0-merror:0.170581\tvalidation_1-merror:0.204545\n",
            "[89]\tvalidation_0-merror:0.17037\tvalidation_1-merror:0.204293\n",
            "[90]\tvalidation_0-merror:0.169634\tvalidation_1-merror:0.204461\n",
            "[91]\tvalidation_0-merror:0.169423\tvalidation_1-merror:0.204545\n",
            "[92]\tvalidation_0-merror:0.169213\tvalidation_1-merror:0.204377\n",
            "[93]\tvalidation_0-merror:0.168624\tvalidation_1-merror:0.204545\n",
            "[94]\tvalidation_0-merror:0.168119\tvalidation_1-merror:0.204377\n",
            "[95]\tvalidation_0-merror:0.167908\tvalidation_1-merror:0.204377\n",
            "[96]\tvalidation_0-merror:0.167551\tvalidation_1-merror:0.204545\n",
            "[97]\tvalidation_0-merror:0.167424\tvalidation_1-merror:0.204461\n",
            "[98]\tvalidation_0-merror:0.167109\tvalidation_1-merror:0.204377\n",
            "[99]\tvalidation_0-merror:0.166561\tvalidation_1-merror:0.204293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL03wDzO4Z7k",
        "colab_type": "code",
        "outputId": "4819f165-74a2-4357-de50-935fa26c17e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.ylim(0,0.3)\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKEsWxhhjgrJkYYwxJihLFsYYY4L6/2r/eVCfs25PAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3dNV6vT460p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7-ml6BhRRf",
        "colab_type": "text"
      },
      "source": [
        "## Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    }
  ]
}